{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26229,
     "status": "error",
     "timestamp": 1547728559669,
     "user": {
      "displayName": "yuan jui huang",
      "photoUrl": "",
      "userId": "00178973905409927419"
     },
     "user_tz": -480
    },
    "id": "RXQqxdbLNubd",
    "outputId": "4b2b5b72-545c-4df5-d2a4-5578f44ddda5"
   },
   "outputs": [],
   "source": [
    "# Mask R-CNN reference code\n",
    "# https://www.cnblogs.com/hellcat/p/9987442.html\n",
    "\n",
    "\n",
    "# the reference web of Colab with google drive : https://www.jianshu.com/p/ce2e63d1c10c\n",
    "# 戴入檔案的方式， \n",
    "# COLAB  0:從Local端的路徑  \n",
    "#       1:從Google Drive 中載入 \n",
    "\n",
    "import os\n",
    "\n",
    "IS_COLAB = 0\n",
    "\n",
    "if IS_COLAB == 1:\n",
    "  !apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "  !add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "  !apt-get update -qq 2>&1 > /dev/null\n",
    "  !apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "  from google.colab import auth\n",
    "  auth.authenticate_user()\n",
    "  from oauth2client.client import GoogleCredentials\n",
    "  creds = GoogleCredentials.get_application_default()\n",
    "  import getpass\n",
    "  !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "  vcode = getpass.getpass()\n",
    "  !echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
    "\n",
    "  !mkdir -p drive\n",
    "  !google-drive-ocamlfuse drive\n",
    "\n",
    "  # 此处为google drive中的文件路径,drive为之前指定的工作根目录，要加上\n",
    "  os.chdir(\"drive/Colab Notebooks/breast_mask_rcnn\") \n",
    "  !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 799,
     "status": "error",
     "timestamp": 1547727783665,
     "user": {
      "displayName": "yuan jui huang",
      "photoUrl": "",
      "userId": "00178973905409927419"
     },
     "user_tz": -480
    },
    "id": "gRrUrn7eMh-N",
    "outputId": "bbd2f9a2-1d0a-4e2b-befc-6f8411991272"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "GPU device not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5252cb93eac3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'/device:GPU:0'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GPU device not found'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Found GPU at: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: GPU device not found"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "91voOp_kLReg"
   },
   "source": [
    "# Create Model and Load Trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExOp-EJsLRek"
   },
   "outputs": [],
   "source": [
    "from mrcnn.config import Config\n",
    "\n",
    "class InferenceConfig(Config):\n",
    "    \n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = 'breast_ultrasound'\n",
    "    BACKBONE = 'resnet50'\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 8\n",
    "    \n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # Background, BI-RADYS 2 , BI-RADYS 3, BI-RADYS 4\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 192  #448\n",
    "    IMAGE_MAX_DIM = 192  #576\n",
    "    #IMAGE_MIN_SCALE = 1.0\n",
    "    IMAGE_CHANNEL_COUNT = 3\n",
    "    \n",
    "    # Image mean (grau)\n",
    "    #MEAN_PIXEL = np.array([128])\n",
    "    \n",
    "    DETECTION_MAX_INSTANCES = 100 #100\n",
    "    \n",
    "    MAX_GT_INSTANCES = 100 # 100   \n",
    "    \n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (32, 64, 128, 192)  # anchor side in pixels 128\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 4 #32\n",
    "    \n",
    "    # How many anchors per image to use for RPN training\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 8  #64\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 200\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 200\n",
    "    \n",
    "    # Don't resize imager for inferencing\n",
    "    IMAGE_RESIZE_MODE = \"pad64\"\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58cdYeYULRe3"
   },
   "outputs": [],
   "source": [
    "\n",
    "ROOT_DIR = os.path.abspath(\".\")\n",
    "\n",
    "print (\"ROOT  DIR : \", (ROOT_DIR))\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "print ('MODEL DIR : ', MODEL_DIR )\n",
    "\n",
    "\n",
    "# Directory of images to run detection on\n",
    "TRAIN_IMAGE_DIR = os.path.join(ROOT_DIR, \"images/train\")\n",
    "print ('TRAIN IMAGE DIR : ', TRAIN_IMAGE_DIR )\n",
    " \n",
    "VALID_IMAGE_DIR = os.path.join(ROOT_DIR, \"images/valid\")\n",
    "print ('VALID IMAGE DIR : ', VALID_IMAGE_DIR )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gz78IpK4LRfH"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from os import path\n",
    "from os.path import join \n",
    "\n",
    "class BreastUltrasoundDataset(utils.Dataset):\n",
    "    IMAGE_WIDTH = 192\n",
    "    IMAGE_HEIGHT = 192\n",
    "    \n",
    "    def inital_dataset(self, data_set):        \n",
    "        # Add classes\n",
    "        self.add_class(\"breast_ultrasound\", 1, \"BI-RAYS:2\")       \n",
    "        self.add_class(\"breast_ultrasound\", 2, \"BI-RAYS:3\")\n",
    "        self.add_class(\"breast_ultrasound\", 3, \"BI-RAYS:4\")\n",
    "         \n",
    "        img_count = 0\n",
    "        for bi_rays in ['2','3']:\n",
    "            img_count = 0\n",
    "            bi_rays_path = join(data_set, bi_rays)             \n",
    "            print (bi_rays_path)\n",
    "            file_names = next(os.walk(bi_rays_path))[2]             \n",
    "            for index, file in enumerate(file_names):\n",
    "                if file.endswith('.jpg') and \"_mask\" not in file:\n",
    "                    split_file = file.split('.')\n",
    "                    mask_file = split_file[0]+\"_mask.\"+split_file[1]  \n",
    "                    mask_file = join(bi_rays_path, mask_file)                     \n",
    "                    if path.exists(mask_file):\n",
    "                      self.add_image(\"breast_ultrasound\", image_id=index, \\\n",
    "                                      path=os.path.join(bi_rays_path, file), \\\n",
    "                                      birays=int(bi_rays)-1)    \n",
    "                      img_count+=1\n",
    "            print (\"BI-RAYS:{} Image Count:{}\".format(bi_rays, img_count))\n",
    "     \n",
    "    def load_image(self, image_id):      \n",
    "        info = self.image_info[image_id] \n",
    "        img = None\n",
    "        if os.path.exists(info['path']):       \n",
    "            img = cv2.imread(info['path'])\n",
    "            img = cv2.resize(img, (self.IMAGE_WIDTH, self.IMAGE_HEIGHT))\n",
    "        return img\n",
    "    \n",
    "    \n",
    "    def image_reference(self, image_id):        \n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"breast_ultrasound\":\n",
    "            return info[\"breast_ultrasound\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]  \n",
    "        img = None\n",
    "        orig_path = info['path']\n",
    "        dot_index = orig_path.rfind('.')\n",
    "        mask_path = orig_path[0:dot_index] + '_mask' + orig_path[dot_index:]    \n",
    "        \n",
    "        birays = info['birays']\n",
    "        class_ids = [birays] \n",
    "        mask_lists=[]\n",
    "        if os.path.exists(mask_path):  \n",
    "            mask = cv2.imread(mask_path)     \n",
    "            mask = cv2.resize(mask, (self.IMAGE_WIDTH, self.IMAGE_HEIGHT))\n",
    "            mask =cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)                 \n",
    "            mask_lists=[mask.astype(np.bool)]            \n",
    "        \n",
    "        mask = np.stack(mask_lists, axis=-1)         \n",
    "        return mask, np.array(class_ids).astype(np.int32)\n",
    "         \n",
    "data_set = BreastUltrasoundDataset() \n",
    "data_set.inital_dataset(TRAIN_IMAGE_DIR)\n",
    "data_set.prepare()\n",
    "\n",
    "print ('=== train data ===')\n",
    "for image_id in [0,1,2]:\n",
    "    image = data_set.load_image(image_id)      \n",
    "    mask, class_ids = data_set.load_mask(image_id)     \n",
    "    visualize.display_top_masks(image, mask, class_ids, data_set.class_names) \n",
    "\n",
    "for image_id in [300,301,302]:\n",
    "    image = data_set.load_image(image_id)      \n",
    "    mask, class_ids = data_set.load_mask(image_id)     \n",
    "    visualize.display_top_masks(image, mask, class_ids, data_set.class_names) \n",
    "    \n",
    "valid_data_set = BreastUltrasoundDataset()\n",
    "valid_data_set.inital_dataset(VALID_IMAGE_DIR)\n",
    "valid_data_set.prepare()\n",
    "print ('=== valid data ===')\n",
    "for image_id in [0,1,2]:\n",
    "    image = valid_data_set.load_image(image_id)      \n",
    "    mask, class_ids = valid_data_set.load_mask(image_id)     \n",
    "    visualize.display_top_masks(image, mask, class_ids, valid_data_set.class_names)     \n",
    "    \n",
    "for image_id in[200,201,202]:\n",
    "    image = valid_data_set.load_image(image_id)      \n",
    "    mask, class_ids = valid_data_set.load_mask(image_id)     \n",
    "    visualize.display_top_masks(image, mask, class_ids, valid_data_set.class_names) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WT8sTImcLRfa"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create model object in inference mode. inference training\n",
    "model = modellib.MaskRCNN(mode=\"training\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Which weights to start with?\n",
    "init_with = \"last\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"last\":\n",
    "    print (model.find_last())\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hwRbzXUELRfo",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "model.train(data_set, valid_data_set, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=261, \n",
    "            layers=\"all\") #\"heads\" \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fd4OgvJ0NnMa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6DHpeQ76LRf0"
   },
   "outputs": [],
   "source": [
    "class InferenceConfig2(InferenceConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1 \n",
    "    BATCH_SIZE = 1\n",
    "\n",
    "config2 = InferenceConfig2()\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config2)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()\n",
    "print (model_path)\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hYh3Tw28NMqY"
   },
   "outputs": [],
   "source": [
    "image_id=0\n",
    "\n",
    "image = data_set.load_image(image_id) \n",
    "\n",
    "print (image.shape)\n",
    "\n",
    "results = model.detect([image], verbose=1)\n",
    "print (len(results))\n",
    "r = results[0]\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                           'test', r['scores'], figsize=(8, 8) ) #ax=get_ax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vd--NsZlLRgA"
   },
   "outputs": [],
   "source": [
    "image_id=0\n",
    "image = valid_data_set.load_image(image_id) \n",
    "print (image.shape)\n",
    "results = model.detect([image], verbose=1)\n",
    "\n",
    "print (len(results))\n",
    "r = results[0]\n",
    "\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                           'test', r['scores'], figsize=(8, 8) ) #ax=get_ax()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5bdm0Fk8LRgN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "breast_ultrasound_by_mask_r_cnn.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
